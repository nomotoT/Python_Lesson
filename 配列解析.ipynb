{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "配列解析.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nomotoT/Python_Lesson/blob/master/%E9%85%8D%E5%88%97%E8%A7%A3%E6%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZy2bT2S1IeD",
        "colab_type": "text"
      },
      "source": [
        "7. 実践編: ディープラーニングを使った配列解析\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mSTDoVT05su",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "bbde2e94-cf96-4c9a-ca28-f90c84f31de1"
      },
      "source": [
        "!curl https://colab.chainer.org/install | sh -"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1580  100  1580    0     0   9028      0 --:--:-- --:--:-- --:--:--  9080\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3fSHtYd1BbK",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDLzScA71rVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "fa50c219-0959-48ae-9f5f-c307f2e42599"
      },
      "source": [
        "import chainer\n",
        "import cupy\n",
        "import matplotlib\n",
        "\n",
        "chainer.print_runtime_info()\n",
        "print('matplotlib:', matplotlib.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Platform: Linux-4.14.79+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Chainer: 5.4.0\n",
            "NumPy: 1.16.3\n",
            "CuPy:\n",
            "  CuPy Version          : 5.4.0\n",
            "  CUDA Root             : /usr/local/cuda\n",
            "  CUDA Build Version    : 10000\n",
            "  CUDA Driver Version   : 10000\n",
            "  CUDA Runtime Version  : 10000\n",
            "  cuDNN Build Version   : 7301\n",
            "  cuDNN Version         : 7301\n",
            "  NCCL Build Version    : 2402\n",
            "  NCCL Runtime Version  : 2402\n",
            "iDeep: 2.0.0.post3\n",
            "matplotlib: 3.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVX1uOZu1s7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "3bb3ff0b-ac81-4587-b9ef-89316bf96bf2"
      },
      "source": [
        "!wget https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/seq.h5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-21 05:25:08--  https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/seq.h5\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/c79a0800-f713-11e8-8d6c-255563d45b1b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190521%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190521T052509Z&X-Amz-Expires=300&X-Amz-Signature=e91f87f03db6b4df30c446dda415065aceb265989340b01bedd8acffbfe94b21&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dseq.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-05-21 05:25:09--  https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/c79a0800-f713-11e8-8d6c-255563d45b1b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190521%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190521T052509Z&X-Amz-Expires=300&X-Amz-Signature=e91f87f03db6b4df30c446dda415065aceb265989340b01bedd8acffbfe94b21&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dseq.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.0.51\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.0.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 594118876 (567M) [application/octet-stream]\n",
            "Saving to: ‘seq.h5’\n",
            "\n",
            "seq.h5              100%[===================>] 566.60M  84.2MB/s    in 6.9s    \n",
            "\n",
            "2019-05-21 05:25:16 (82.5 MB/s) - ‘seq.h5’ saved [594118876/594118876]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynLJOQK32a_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1ee9e840-3776-4bd8-ed31-b87b60bd8f18"
      },
      "source": [
        "\n",
        "!ls -lh\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 567M\n",
            "drwxr-xr-x 1 root root 4.0K May 15 16:23 sample_data\n",
            "-rw-r--r-- 1 root root 567M Dec  3 06:54 seq.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bTiZfnJ2nPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc807a9c-4757-40b0-9357-28b9aa99bebc"
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  seq.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDRpnmHZ4G94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "0940c327-bffc-44c1-bb99-4eb6a31fa1a8"
      },
      "source": [
        "%cd sample_data\n",
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/sample_data\n",
            "anscombe.json\t\t      mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyPY7FzW5k_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cca69eef-34d6-41ed-8952-3866a03abf46"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6pLVo5e5rRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ed098630-fc01-4e78-984d-72700b8a1816"
      },
      "source": [
        "# h5ファイルを操作するライブラリー\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "with h5py.File('seq.h5', 'r') as hf:\n",
        "    for key in hf.keys():\n",
        "        print(key, hf[key].shape, hf[key].dtype)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target_labels (10,) |S29\n",
            "test_in (500, 131072, 4) bool\n",
            "test_out (500, 1024, 10) float16\n",
            "train_in (5000, 131072, 4) bool\n",
            "train_out (5000, 1024, 10) float16\n",
            "valid_in (500, 131072, 4) bool\n",
            "valid_out (500, 1024, 10) float16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQUCPUqv66Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z6lvLWn7R2b",
        "colab_type": "text"
      },
      "source": [
        "各データの名前にtrain（学習），validate（検証），test（テスト）の接頭辞がつけられ，inが入力の塩基配列，outが出力のカバレッジ値に対応します．\n",
        "\n",
        "例えば，’train_in’は学習用の入力データであり(5000, 131072, 4)というサイズを持ちます．これは長さが130172からなる配列が5000個あり，それぞれA, T, C, Gの対応する次元の値が1, それ以外は0であるような配列です．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nofkTfju7Q0c",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k_r9II07USe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "166e9c06-2c41-470a-fbf0-9f29957e39fc"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with h5py.File('seq.h5') as hf:\n",
        "    y = hf['train_out'][:100]\n",
        "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "    fig_size[0] = 20\n",
        "    fig_size[1] = 5\n",
        "    for i in range(3):\n",
        "        plt.bar(range(y.shape[1]), y[0,:,i])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAEyCAYAAABtUMC9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAAAAEADhEAAAAAADfj/E2/yms8w4q4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF75QcoM72Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCVwoImo8YYs",
        "colab_type": "text"
      },
      "source": [
        "‘train_out’は学習用の出力データであり,（’5000, 1024, 10’)というサイズを持ちます.これは長さが1024からなる配列が5000個あり,それぞれが10種類の異なるChIP-Seqの結果のカバレッジ値が格納されています.\n",
        "h5py形式のファイルをnumpyデータとして扱うには，コピーする必要があります．以下のコードは’train_in’というキーに対応するテンソルデータをnumpyデータとして読み出し，そのデータの一部を表示します．\n",
        "試しに最初のデータを取り出して，それの出力の値を表示してみます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGh4TG0w8Z4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UNAVfC69h27",
        "colab_type": "text"
      },
      "source": [
        "7.4.3. ブロック\n",
        "\n",
        "それでは最初に，ネットワークの全体を設計します． このネットワークは二つのブロックから構成されます．\n",
        "\n",
        "１つ目のブロックは長さが   \n",
        "から配列を入力として長さが   のベクトルを出力とします．これにより入力の128 (     \n",
        "\n",
        ")bpが出力の1つの位置に対応するようになります．これを実現しているのが，SqueezeBlockです．すなわち，SqueezeBlockは長さ131072bpからなるDNAの塩基配列を入力として受け取り，各フラグメントの長さに相当する128bp毎の情報が一つの値となるような畳込み処理を行います．結果として131072/128=1024の長さのベクトル列が出力されます．このベクトル列はフラグメント毎の特徴が一つのベクトルに圧縮されたものとみなすことができます．\n",
        "\n",
        "二つ目のブロックは遠距離にある情報を考慮して各ベクトルの値を計算していく部分であり，DilatedBlockが担当します．DilatedBlockは，SqueezeBlockから出力された1024の長さのベクトル列を受け取り，Dilated Convolutionの仕組みを使うことで互いに離れた位置の情報を効率的に考慮した上で処理していき，入力と同じ1024の長さの出力を返します．この出力が，フラグメント毎に与えられたDNA関連タンパク質の結合可能性を表す数値（カバレッジ値）と一致するように学習を進めます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm3cmSmC9l0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "import cupy as cp\n",
        "\n",
        "bc = 24 # base channel\n",
        "\n",
        "default_squeeze_params = [\n",
        "    # out_ch, kernel, stride, dropout\n",
        "    [bc*2, 21, 2, 0], #1 128 -> 64\n",
        "    [int(bc*2.5), 7, 4, 0.05], #2  64 -> 16\n",
        "    [int(bc*3.2), 7, 4, 0.05], #3  16 -> 4\n",
        "    [bc*4, 7, 4, 0.05]  #4  4 -> 1\n",
        "]\n",
        "\n",
        "\n",
        "default_dilated_params = [\n",
        "# out_ch, kernel, dilated\n",
        "  [bc, 3, 1, 0.1],\n",
        "  [bc, 3, 2, 0.1],\n",
        "  [bc, 3, 4, 0.1],\n",
        "  [bc, 3, 8, 0.1],\n",
        "  [bc, 3, 16, 0.1],\n",
        "  [bc, 3, 32, 0.1],\n",
        "  [bc, 3, 64, 0.1]\n",
        "]\n",
        "\n",
        "\n",
        "class Net(chainer.Chain):\n",
        "\n",
        "    def __init__(self, squeeze_params=default_squeeze_params, dilated_params=default_dilated_params, n_targets=10):\n",
        "        super(Net, self).__init__()\n",
        "        self._n_squeeze = len(squeeze_params)\n",
        "        self._n_dilated = len(dilated_params)\n",
        "        with self.init_scope():\n",
        "            in_ch = 4\n",
        "            for i, param in enumerate(squeeze_params):\n",
        "                out_ch, kernel, stride, do_rate = param\n",
        "                setattr(self, \"s_{}\".format(i), SqueezeBlock(in_ch, out_ch, kernel, stride, do_rate))\n",
        "                in_ch = out_ch\n",
        "            for i, param in enumerate(dilated_params):\n",
        "                out_ch, kernel, dilated, do_rate = param\n",
        "                setattr(self, \"d_{}\".format(i), DilatedBlock(in_ch, out_ch, kernel, dilated, do_rate))\n",
        "                in_ch += out_ch\n",
        "            self.l = L.ConvolutionND(1, None, n_targets, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x : (B, X, 4)\n",
        "        xp = cp.get_array_module(x)\n",
        "        h = xp.transpose(x, (0, 2, 1))\n",
        "        h = h.astype(xp.float32)\n",
        "\n",
        "        for i in range(self._n_squeeze):\n",
        "            h = self[\"s_{}\".format(i)](h)\n",
        "\n",
        "        hs = [h]\n",
        "        for i in range(self._n_dilated):\n",
        "            h = self[\"d_{}\".format(i)](hs)\n",
        "            hs.append(h)\n",
        "\n",
        "        h = self.l(F.concat(hs, axis=1))\n",
        "        h = xp.transpose(h, (0, 2, 1))\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk3QMKFd90xQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "import cupy as cp\n",
        "\n",
        "class WNConvolutionND(L.ConvolutionND):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(WNConvolutionND, self).__init__(*args, **kwargs)\n",
        "        self.add_param('g', self.W.data.shape[0])\n",
        "        norm = np.linalg.norm(self.W.data.reshape(\n",
        "            self.W.data.shape[0], -1), axis=1)\n",
        "        self.g.data[...] = norm\n",
        "\n",
        "    def __call__(self, x):\n",
        "        norm = F.batch_l2_norm_squared(self.W) ** 0.5\n",
        "        channel_size = self.W.data.shape[0]\n",
        "        norm_broadcasted = F.broadcast_to(\n",
        "            F.reshape(norm, (channel_size, 1, 1)), self.W.data.shape)\n",
        "        g_broadcasted = F.broadcast_to(\n",
        "            F.reshape(self.g, (channel_size, 1, 1)), self.W.data.shape)\n",
        "        return F.convolution_nd(\n",
        "            x, g_broadcasted * self.W / norm_broadcasted, self.b, self.stride,\n",
        "            self.pad, self.cover_all, self.dilate)\n",
        "\n",
        "class SqueezeBlock(chainer.Chain):\n",
        "    def __init__(self, in_ch, out_ch, kernel, stride, do_rate):\n",
        "        super(SqueezeBlock, self).__init__()\n",
        "\n",
        "        self.do_rate = do_rate\n",
        "        with self.init_scope():\n",
        "            pad = kernel // 2\n",
        "            self.conv = WNConvolutionND(1, in_ch, out_ch*2, kernel, pad=pad, stride=stride)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.conv(x)\n",
        "        h, g = F.split_axis(h, 2, 1)\n",
        "        h = F.dropout(h * F.sigmoid(g), self.do_rate)\n",
        "        return h\n",
        "\n",
        "class DilatedBlock(chainer.Chain):\n",
        "     def __init__(self, in_ch, out_ch, kernel, dilate, do_rate):\n",
        "        super(DilatedBlock, self).__init__()\n",
        "        self.do_rate = do_rate\n",
        "        with self.init_scope():\n",
        "            self.conv = WNConvolutionND(1, in_ch, out_ch*2, kernel, pad=dilate, dilate=dilate)\n",
        "\n",
        "     def forward(self, xs):\n",
        "        x = F.concat(xs, axis=1)\n",
        "        h = self.conv(x)\n",
        "        h, g = F.split_axis(h, 2, 1)\n",
        "        h = F.dropout(h * F.sigmoid(g), self.do_rate)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhmKHyDb-OBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2527241d-82b7-4dba-a3ee-53e546accde8"
      },
      "source": [
        "import numpy as np\n",
        "n = Net()\n",
        "size = 131072 # 128 * 1024\n",
        "batchsize = 4\n",
        "x = np.empty((batchsize, size, 4), dtype=np.bool)\n",
        "y = n.forward(x)\n",
        "print(y.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 1024, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUFQmvI0-jEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer.functions as F\n",
        "import math\n",
        "import sklearn\n",
        "import numpy as np\n",
        "\n",
        "def log_poisson_loss(log_x, t):\n",
        "    loss =  F.mean(F.exp(log_x) - t * log_x)\n",
        "    t = chainer.cuda.to_cpu(t.astype(np.float32))\n",
        "    offset = F.mean(cp.array(t - t * np.ma.log(t)))\n",
        "    return loss - offset\n",
        "\n",
        "\n",
        "def log_r2_score(log_x, t):\n",
        "    return F.r2_score(F.exp(log_x), t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcTcsjnd-26w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from chainer import training\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class CosineScheduler(training.Extension):\n",
        "\n",
        "    def __init__(self, attr='lr', init_val=0.0001, n_decays=200, n_warmups=3, target=None, optimizer=None):\n",
        "        self._attr = attr\n",
        "        self._target = target\n",
        "        self._optimizer = optimizer\n",
        "        self._min_loss = None\n",
        "        self._last_value = None\n",
        "        self._init_val = init_val\n",
        "        self._n_decays = n_decays - n_warmups\n",
        "        self._decay_count = 0\n",
        "        self._n_warmups = n_warmups\n",
        "\n",
        "    def __call__(self, trainer):\n",
        "        updater = trainer.updater\n",
        "        optimizer = self._get_optimizer(trainer)\n",
        "        epoch = updater.epoch\n",
        "        if epoch < self._n_warmups:\n",
        "            value = self._init_val / (self._n_warmups + 1) * (epoch + 1)\n",
        "        else:\n",
        "            value = 0.5 * self._init_val * (1 + math.cos(math.pi * (epoch - self._n_warmups) / self._n_decays))\n",
        "        self._update_value(optimizer, value)\n",
        "\n",
        "\n",
        "    def _get_optimizer(self, trainer):\n",
        "        return self._optimizer or trainer.updater.get_optimizer('main')\n",
        "\n",
        "    def _update_value(self, optimizer, value):\n",
        "        setattr(optimizer, self._attr, value)\n",
        "        self._last_value = value\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T53zc-au_B7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer\n",
        "import random\n",
        "\n",
        "class PreprocessedDataset(chainer.dataset.DatasetMixin):\n",
        "\n",
        "    def __init__(self, xs, ys, max_shift):\n",
        "        self.xs = xs\n",
        "        self.ys = ys\n",
        "        self.max_shift = max_shift\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xs)\n",
        "\n",
        "    def get_example(self, i):\n",
        "        # It applies following preprocesses:\n",
        "        #     - Cropping\n",
        "        #     - Random flip\n",
        "\n",
        "        x = self.xs[i]\n",
        "        y = self.ys[i]\n",
        "\n",
        "\n",
        "        s = random.randint(-self.max_shift, self.max_shift)\n",
        "        x = np.roll(x, s, axis=0)\n",
        "        return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NztbUIxN_NjQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4359
        },
        "outputId": "5fb297ac-858d-462c-811a-49e97b9be935"
      },
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "import numpy as np\n",
        "from chainer.training import extensions\n",
        "from chainer import training\n",
        "import h5py\n",
        "\n",
        "ml_h5 = h5py.File('seq.h5')\n",
        "\n",
        "train_x = ml_h5['train_in']\n",
        "train_y = ml_h5['train_out']\n",
        "\n",
        "valid_x = ml_h5['valid_in']\n",
        "valid_y = ml_h5['valid_out']\n",
        "\n",
        "test_x = ml_h5['test_in']\n",
        "test_y = ml_h5['test_out']\n",
        "\n",
        "ratio = 1\n",
        "train_x = train_x[:len(train_x)//ratio]\n",
        "train_y = train_y[:len(train_y)//ratio]\n",
        "valid_x = valid_x[:len(valid_x)//ratio]\n",
        "valid_y = valid_y[:len(valid_y)//ratio]\n",
        "\n",
        "\n",
        "max_shift_for_data_augmentation = 5\n",
        "train = PreprocessedDataset(train_x, train_y, max_shift_for_data_augmentation)\n",
        "val = chainer.datasets.TupleDataset(valid_x, valid_y)\n",
        "\n",
        "batchsize = 8\n",
        "\n",
        "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
        "val_iter = chainer.iterators.SerialIterator(val, batchsize, repeat=False, shuffle=False)\n",
        "\n",
        "model = L.Classifier(Net(), lossfun=log_poisson_loss, accfun=log_r2_score)\n",
        "\n",
        "lr = 0.001\n",
        "optimizer = chainer.optimizers.Adam(alpha=lr, beta1=0.97, beta2=0.98)\n",
        "optimizer.setup(model)\n",
        "optimizer.add_hook(chainer.optimizer_hooks.GradientClipping(threshold=0.01))\n",
        "\n",
        "\n",
        "updater = training.updaters.StandardUpdater(\n",
        "     train_iter, optimizer, device=0)\n",
        "\n",
        "n_epochs = 50       # エポック数\n",
        "n_warmups = 0\n",
        "out = \"out\"\n",
        "trainer = training.Trainer(updater, (n_epochs, 'epoch'), out=out)\n",
        "trainer.extend(CosineScheduler(attr='alpha', init_val=lr, n_decays=n_epochs, n_warmups=n_warmups), trigger=(1, 'epoch'))\n",
        "\n",
        "trainer.extend(extensions.Evaluator(val_iter, model, device = 0))\n",
        "trainer.extend(extensions.LogReport(trigger=(0.2, 'epoch')))\n",
        "trainer.extend(extensions.snapshot_object(model, 'model_epoch_{.updater.epoch}'), trigger=(1, 'epoch'))\n",
        "\n",
        "trainer.extend(extensions.PrintReport(\n",
        "          ['epoch', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger = (0.1, 'epoch'))\n",
        "\n",
        "# trainer.extend(extensions.ProgressBar())\n",
        "\n",
        "trainer.run()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/loss   validation/main/loss  elapsed_time\n",
            "\u001b[J0           2.08463                           18.9531       \n",
            "\u001b[J0           1.91625                           37.6061       \n",
            "\u001b[J0           1.88729                           55.9476       \n",
            "\u001b[J0           1.79833                           73.9485       \n",
            "\u001b[J1           1.86589     1.83787               96.2814       \n",
            "\u001b[J1           1.73605                           114.921       \n",
            "\u001b[J1           1.82446                           133.63        \n",
            "\u001b[J1           1.80308                           152.165       \n",
            "\u001b[J1           1.72354                           170.852       \n",
            "\u001b[J2           1.75214     1.76814               193.369       \n",
            "\u001b[J2           1.70355                           212.046       \n",
            "\u001b[J2           1.66726                           230.91        \n",
            "\u001b[J2           1.73203                           249.568       \n",
            "\u001b[J2           1.72203                           268.25        \n",
            "\u001b[J3           1.72042     1.74184               290.983       \n",
            "\u001b[J3           1.65812                           309.599       \n",
            "\u001b[J3           1.61657                           328.573       \n",
            "\u001b[J3           1.6473                            347.408       \n",
            "\u001b[J3           1.68501                           366.32        \n",
            "\u001b[J4           1.73071     1.71986               389.05        \n",
            "\u001b[J4           1.65609                           407.843       \n",
            "\u001b[J4           1.62381                           426.463       \n",
            "\u001b[J4           1.64509                           445.582       \n",
            "\u001b[J4           1.66935                           464.389       \n",
            "\u001b[J5           1.606       1.72193               487.101       \n",
            "\u001b[J5           1.66616                           505.892       \n",
            "\u001b[J5           1.64349                           524.704       \n",
            "\u001b[J5           1.59351                           543.644       \n",
            "\u001b[J5           1.65635                           562.445       \n",
            "\u001b[J6           1.62273     1.69308               585.127       \n",
            "\u001b[J6           1.62257                           604.1         \n",
            "\u001b[J6           1.57499                           622.77        \n",
            "\u001b[J6           1.6638                            641.851       \n",
            "\u001b[J6           1.623                             660.679       \n",
            "\u001b[J7           1.65317     1.65156               683.495       \n",
            "\u001b[J7           1.64072                           702.285       \n",
            "\u001b[J7           1.58301                           721.085       \n",
            "\u001b[J7           1.60461                           739.972       \n",
            "\u001b[J7           1.60653                           759.015       \n",
            "\u001b[J8           1.58364     1.63311               781.898       \n",
            "\u001b[J8           1.59893                           800.692       \n",
            "\u001b[J8           1.56912                           819.571       \n",
            "\u001b[J8           1.64231                           838.465       \n",
            "\u001b[J8           1.54177                           857.294       \n",
            "\u001b[J9           1.60366     1.6128                880.238       \n",
            "\u001b[J9           1.55543                           899.213       \n",
            "\u001b[J9           1.62395                           918.091       \n",
            "\u001b[J9           1.57358                           937.129       \n",
            "\u001b[J9           1.57741                           956.044       \n",
            "\u001b[J10          1.57753     1.62092               979.078       \n",
            "\u001b[J10          1.54285                           997.954       \n",
            "\u001b[J10          1.61027                           1017          \n",
            "\u001b[J10          1.60515                           1035.9        \n",
            "\u001b[J10          1.5494                            1054.74       \n",
            "\u001b[J11          1.5724      1.60784               1077.76       \n",
            "\u001b[J11          1.57153                           1096.78       \n",
            "\u001b[J11          1.52874                           1115.68       \n",
            "\u001b[J11          1.58923                           1134.55       \n",
            "\u001b[J11          1.53384                           1153.33       \n",
            "\u001b[J12          1.53282     1.60122               1176.44       \n",
            "\u001b[J12          1.55218                           1195.36       \n",
            "\u001b[J12          1.54764                           1214.27       \n",
            "\u001b[J12          1.55385                           1233.26       \n",
            "\u001b[J12          1.52473                           1252.15       \n",
            "\u001b[J13          1.5068      1.58006               1275.23       \n",
            "\u001b[J13          1.51209                           1294.15       \n",
            "\u001b[J13          1.47392                           1313.1        \n",
            "\u001b[J13          1.55667                           1332.13       \n",
            "\u001b[J13          1.57702                           1350.98       \n",
            "\u001b[J14          1.52474     1.59242               1373.83       \n",
            "\u001b[J14          1.49323                           1392.74       \n",
            "\u001b[J14          1.53947                           1411.75       \n",
            "\u001b[J14          1.52709                           1430.63       \n",
            "\u001b[J14          1.49102                           1449.58       \n",
            "\u001b[J15          1.50554     1.54753               1472.37       \n",
            "\u001b[J15          1.4857                            1491.41       \n",
            "\u001b[J15          1.51021                           1510.3        \n",
            "\u001b[J15          1.4671                            1529.25       \n",
            "\u001b[J15          1.4957                            1548.12       \n",
            "\u001b[J16          1.50143     1.54618               1571.01       \n",
            "\u001b[J16          1.44218                           1589.98       \n",
            "\u001b[J16          1.46452                           1608.91       \n",
            "\u001b[J16          1.47355                           1627.66       \n",
            "\u001b[J16          1.46965                           1646.74       \n",
            "\u001b[J17          1.54641     1.54013               1669.65       \n",
            "\u001b[J17          1.46759                           1688.6        \n",
            "\u001b[J17          1.47035                           1707.48       \n",
            "\u001b[J17          1.44104                           1726.23       \n",
            "\u001b[J17          1.50938                           1745.33       \n",
            "\u001b[J18          1.49484     1.53334               1768.18       \n",
            "\u001b[J18          1.46504                           1787.08       \n",
            "\u001b[J18          1.48214                           1805.96       \n",
            "\u001b[J18          1.49733                           1824.85       \n",
            "\u001b[J18          1.46248                           1843.86       \n",
            "\u001b[J19          1.42256     1.54778               1866.65       \n",
            "\u001b[J19          1.47043                           1885.68       \n",
            "\u001b[J19          1.45057                           1904.72       \n",
            "\u001b[J19          1.44521                           1923.44       \n",
            "\u001b[J19          1.43797                           1942.46       \n",
            "\u001b[J20          1.45807     1.50684               1965.22       \n",
            "\u001b[J20          1.42086                           1984.29       \n",
            "\u001b[J20          1.44944                           2003.16       \n",
            "\u001b[J20          1.43675                           2021.88       \n",
            "\u001b[J20          1.48307                           2040.93       \n",
            "\u001b[J21          1.43847     1.50468               2063.9        \n",
            "\u001b[J21          1.41041                           2082.78       \n",
            "\u001b[J21          1.45312                           2101.71       \n",
            "\u001b[J21          1.45214                           2120.45       \n",
            "\u001b[J21          1.44768                           2139.67       \n",
            "\u001b[J22          1.4323      1.4951                2162.41       \n",
            "\u001b[J22          1.40273                           2181.26       \n",
            "\u001b[J22          1.41573                           2200.3        \n",
            "\u001b[J22          1.43232                           2219.08       \n",
            "\u001b[J22          1.44065                           2238.05       \n",
            "\u001b[J23          1.45214     1.49356               2260.79       \n",
            "\u001b[J23          1.41922                           2279.75       \n",
            "\u001b[J23          1.44213                           2298.71       \n",
            "\u001b[J23          1.42399                           2317.43       \n",
            "\u001b[J23          1.41109                           2336.49       \n",
            "\u001b[J24          1.42561     1.49408               2359.35       \n",
            "\u001b[J24          1.42502                           2378.42       \n",
            "\u001b[J24          1.43372                           2397.35       \n",
            "\u001b[J24          1.41626                           2416.11       \n",
            "\u001b[J24          1.39902                           2435.21       \n",
            "\u001b[J25          1.41733     1.49227               2458.13       \n",
            "\u001b[J25          1.44522                           2477.05       \n",
            "\u001b[J25          1.39451                           2495.96       \n",
            "\u001b[J25          1.4092                            2514.85       \n",
            "\u001b[J25          1.39648                           2534.03       \n",
            "\u001b[J26          1.39098     1.49361               2556.9        \n",
            "\u001b[J26          1.41911                           2575.79       \n",
            "\u001b[J26          1.40521                           2594.78       \n",
            "\u001b[J26          1.38687                           2613.78       \n",
            "\u001b[J26          1.43198                           2632.71       \n",
            "\u001b[J27          1.39562     1.48657               2655.5        \n",
            "\u001b[J27          1.38818                           2674.38       \n",
            "\u001b[J27          1.37589                           2693.37       \n",
            "\u001b[J27          1.42126                           2712.35       \n",
            "\u001b[J27          1.43051                           2731.19       \n",
            "\u001b[J28          1.4107      1.49595               2753.99       \n",
            "\u001b[J28          1.40241                           2773          \n",
            "\u001b[J28          1.42576                           2792.05       \n",
            "\u001b[J28          1.3684                            2811.02       \n",
            "\u001b[J28          1.41427                           2830.08       \n",
            "\u001b[J29          1.38341     1.47914               2852.88       \n",
            "\u001b[J29          1.37807                           2871.86       \n",
            "\u001b[J29          1.39206                           2890.78       \n",
            "\u001b[J29          1.4062                            2909.71       \n",
            "\u001b[J29          1.38888                           2928.68       \n",
            "\u001b[J30          1.37699     1.47645               2951.65       \n",
            "\u001b[J30          1.41408                           2970.58       \n",
            "\u001b[J30          1.36549                           2989.51       \n",
            "\u001b[J30          1.35303                           3008.38       \n",
            "\u001b[J30          1.39803                           3027.4        \n",
            "\u001b[J31          1.37895     1.47947               3050.18       \n",
            "\u001b[J31          1.36967                           3069.14       \n",
            "\u001b[J31          1.38841                           3088.04       \n",
            "\u001b[J31          1.37095                           3107.06       \n",
            "\u001b[J31          1.35597                           3126.06       \n",
            "\u001b[J32          1.40661     1.47853               3148.97       \n",
            "\u001b[J32          1.34836                           3167.76       \n",
            "\u001b[J32          1.346                             3186.95       \n",
            "\u001b[J32          1.39543                           3206.01       \n",
            "\u001b[J32          1.36605                           3224.95       \n",
            "\u001b[J33          1.40966     1.47059               3247.79       \n",
            "\u001b[J33          1.36147                           3266.7        \n",
            "\u001b[J33          1.35338                           3285.84       \n",
            "\u001b[J33          1.36957                           3304.77       \n",
            "\u001b[J33          1.37058                           3323.72       \n",
            "\u001b[J34          1.38284     1.48164               3346.68       \n",
            "\u001b[J34          1.35161                           3365.53       \n",
            "\u001b[J34          1.34342                           3384.61       \n",
            "\u001b[J34          1.39919                           3403.56       \n",
            "\u001b[J34          1.36645                           3422.62       \n",
            "\u001b[J35          1.37693     1.47768               3445.67       \n",
            "\u001b[J35          1.36493                           3464.5        \n",
            "\u001b[J35          1.34844                           3483.61       \n",
            "\u001b[J35          1.39289                           3502.67       \n",
            "\u001b[J35          1.33963                           3521.69       \n",
            "\u001b[J36          1.36054     1.46997               3544.56       \n",
            "\u001b[J36          1.34408                           3563.39       \n",
            "\u001b[J36          1.37026                           3582.66       \n",
            "\u001b[J36          1.35572                           3601.62       \n",
            "\u001b[J36          1.36785                           3620.59       \n",
            "\u001b[J37          1.35367     1.46323               3643.45       \n",
            "\u001b[J37          1.34626                           3662.39       \n",
            "\u001b[J37          1.41425                           3681.54       \n",
            "\u001b[J37          1.38427                           3700.48       \n",
            "\u001b[J37          1.31033                           3719.42       \n",
            "\u001b[J38          1.31674     1.50044               3742.38       \n",
            "\u001b[J38          1.34643                           3761.3        \n",
            "\u001b[J38          1.34934                           3780.41       \n",
            "\u001b[J38          1.37027                           3799.35       \n",
            "\u001b[J38          1.34716                           3818.45       \n",
            "\u001b[J39          1.36257     1.46951               3841.4        \n",
            "\u001b[J39          1.32834                           3860.18       \n",
            "\u001b[J39          1.35572                           3879.29       \n",
            "\u001b[J39          1.34648                           3898.27       \n",
            "\u001b[J39          1.35809                           3917.37       \n",
            "\u001b[J40          1.36226     1.46055               3940.24       \n",
            "\u001b[J40          1.31958                           3959.06       \n",
            "\u001b[J40          1.34901                           3978.17       \n",
            "\u001b[J40          1.33628                           3997.31       \n",
            "\u001b[J40          1.36018                           4016.24       \n",
            "\u001b[J41          1.3735      1.46941               4039.08       \n",
            "\u001b[J41          1.35098                           4057.99       \n",
            "\u001b[J41          1.36779                           4077.25       \n",
            "\u001b[J41          1.31676                           4096.19       \n",
            "\u001b[J41          1.32524                           4115.17       \n",
            "\u001b[J42          1.35331     1.47418               4138          \n",
            "\u001b[J42          1.34743                           4156.96       \n",
            "\u001b[J42          1.315                             4176.07       \n",
            "\u001b[J42          1.38435                           4194.98       \n",
            "\u001b[J42          1.33646                           4213.97       \n",
            "\u001b[J43          1.32991     1.46727               4236.93       \n",
            "\u001b[J43          1.34353                           4255.73       \n",
            "\u001b[J43          1.33401                           4274.79       \n",
            "\u001b[J43          1.32243                           4293.77       \n",
            "\u001b[J43          1.35274                           4312.8        \n",
            "\u001b[J44          1.34874     1.46018               4335.61       \n",
            "\u001b[J44          1.36742                           4354.37       \n",
            "\u001b[J44          1.34206                           4373.64       \n",
            "\u001b[J44          1.34148                           4392.68       \n",
            "\u001b[J44          1.28587                           4411.59       \n",
            "\u001b[J45          1.35953     1.4612                4434.47       \n",
            "\u001b[J45          1.33193                           4453.31       \n",
            "\u001b[J45          1.34084                           4472.51       \n",
            "\u001b[J45          1.33862                           4491.43       \n",
            "\u001b[J45          1.33443                           4510.34       \n",
            "\u001b[J46          1.34669     1.46758               4533.19       \n",
            "\u001b[J46          1.30479                           4552.11       \n",
            "\u001b[J46          1.31616                           4571.18       \n",
            "\u001b[J46          1.35809                           4590.14       \n",
            "\u001b[J46          1.34592                           4609.05       \n",
            "\u001b[J47          1.35701     1.46349               4631.97       \n",
            "\u001b[J47          1.30957                           4650.75       \n",
            "\u001b[J47          1.33497                           4669.86       \n",
            "\u001b[J47          1.34995                           4688.92       \n",
            "\u001b[J47          1.35019                           4707.93       \n",
            "\u001b[J48          1.33363     1.46616               4730.87       \n",
            "\u001b[J48          1.32845                           4749.68       \n",
            "\u001b[J48          1.35519                           4768.78       \n",
            "\u001b[J48          1.3307                            4787.78       \n",
            "\u001b[J48          1.33998                           4806.75       \n",
            "\u001b[J49          1.32156     1.467                 4829.64       \n",
            "\u001b[J49          1.35545                           4848.41       \n",
            "\u001b[J49          1.27679                           4867.54       \n",
            "\u001b[J49          1.3409                            4886.5        \n",
            "\u001b[J49          1.35492                           4905.45       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QY1YG8L_Z0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "outputId": "9db21b55-d785-4b22-b407-b577be73e6c5"
      },
      "source": [
        "\n",
        "!ls -l out/\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 71016\n",
            "-rw-r--r-- 1 root root   52332 May 21 07:51 log\n",
            "-rw-r--r-- 1 root root 1446241 May 21 06:31 model_epoch_1\n",
            "-rw-r--r-- 1 root root 1450156 May 21 06:45 model_epoch_10\n",
            "-rw-r--r-- 1 root root 1450364 May 21 06:47 model_epoch_11\n",
            "-rw-r--r-- 1 root root 1450304 May 21 06:49 model_epoch_12\n",
            "-rw-r--r-- 1 root root 1450579 May 21 06:50 model_epoch_13\n",
            "-rw-r--r-- 1 root root 1450725 May 21 06:52 model_epoch_14\n",
            "-rw-r--r-- 1 root root 1450685 May 21 06:54 model_epoch_15\n",
            "-rw-r--r-- 1 root root 1450707 May 21 06:55 model_epoch_16\n",
            "-rw-r--r-- 1 root root 1450964 May 21 06:57 model_epoch_17\n",
            "-rw-r--r-- 1 root root 1450969 May 21 06:59 model_epoch_18\n",
            "-rw-r--r-- 1 root root 1450951 May 21 07:00 model_epoch_19\n",
            "-rw-r--r-- 1 root root 1446519 May 21 06:32 model_epoch_2\n",
            "-rw-r--r-- 1 root root 1451079 May 21 07:02 model_epoch_20\n",
            "-rw-r--r-- 1 root root 1451050 May 21 07:04 model_epoch_21\n",
            "-rw-r--r-- 1 root root 1451125 May 21 07:05 model_epoch_22\n",
            "-rw-r--r-- 1 root root 1450945 May 21 07:07 model_epoch_23\n",
            "-rw-r--r-- 1 root root 1451209 May 21 07:08 model_epoch_24\n",
            "-rw-r--r-- 1 root root 1451336 May 21 07:10 model_epoch_25\n",
            "-rw-r--r-- 1 root root 1451095 May 21 07:12 model_epoch_26\n",
            "-rw-r--r-- 1 root root 1451133 May 21 07:13 model_epoch_27\n",
            "-rw-r--r-- 1 root root 1451100 May 21 07:15 model_epoch_28\n",
            "-rw-r--r-- 1 root root 1451340 May 21 07:17 model_epoch_29\n",
            "-rw-r--r-- 1 root root 1446961 May 21 06:34 model_epoch_3\n",
            "-rw-r--r-- 1 root root 1451127 May 21 07:18 model_epoch_30\n",
            "-rw-r--r-- 1 root root 1451230 May 21 07:20 model_epoch_31\n",
            "-rw-r--r-- 1 root root 1451158 May 21 07:22 model_epoch_32\n",
            "-rw-r--r-- 1 root root 1451250 May 21 07:23 model_epoch_33\n",
            "-rw-r--r-- 1 root root 1451373 May 21 07:25 model_epoch_34\n",
            "-rw-r--r-- 1 root root 1451516 May 21 07:27 model_epoch_35\n",
            "-rw-r--r-- 1 root root 1451182 May 21 07:28 model_epoch_36\n",
            "-rw-r--r-- 1 root root 1451216 May 21 07:30 model_epoch_37\n",
            "-rw-r--r-- 1 root root 1451176 May 21 07:31 model_epoch_38\n",
            "-rw-r--r-- 1 root root 1451305 May 21 07:33 model_epoch_39\n",
            "-rw-r--r-- 1 root root 1447480 May 21 06:36 model_epoch_4\n",
            "-rw-r--r-- 1 root root 1451243 May 21 07:35 model_epoch_40\n",
            "-rw-r--r-- 1 root root 1451546 May 21 07:36 model_epoch_41\n",
            "-rw-r--r-- 1 root root 1451338 May 21 07:38 model_epoch_42\n",
            "-rw-r--r-- 1 root root 1451353 May 21 07:40 model_epoch_43\n",
            "-rw-r--r-- 1 root root 1451465 May 21 07:41 model_epoch_44\n",
            "-rw-r--r-- 1 root root 1451256 May 21 07:43 model_epoch_45\n",
            "-rw-r--r-- 1 root root 1451498 May 21 07:45 model_epoch_46\n",
            "-rw-r--r-- 1 root root 1451370 May 21 07:46 model_epoch_47\n",
            "-rw-r--r-- 1 root root 1451329 May 21 07:48 model_epoch_48\n",
            "-rw-r--r-- 1 root root 1451421 May 21 07:50 model_epoch_49\n",
            "-rw-r--r-- 1 root root 1448012 May 21 06:37 model_epoch_5\n",
            "-rw-r--r-- 1 root root 1451361 May 21 07:51 model_epoch_50\n",
            "-rw-r--r-- 1 root root 1448578 May 21 06:39 model_epoch_6\n",
            "-rw-r--r-- 1 root root 1449089 May 21 06:40 model_epoch_7\n",
            "-rw-r--r-- 1 root root 1449557 May 21 06:42 model_epoch_8\n",
            "-rw-r--r-- 1 root root 1449908 May 21 06:44 model_epoch_9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95zlaeInELV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0d5e6be9-808f-48ee-800f-4b9758e7cfd7"
      },
      "source": [
        "import chainer\n",
        "import chainer.links as L\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_n_epoch = 10\n",
        "out_dir = 'out'\n",
        "model = L.Classifier(Net())\n",
        "chainer.serializers.load_npz('{}/model_epoch_{}'.format(out_dir, model_n_epoch), model)\n",
        "predictor = model.predictor\n",
        "\n",
        "print(len(test_x))\n",
        "with chainer.no_backprop_mode():\n",
        "    test_y_estimated = F.exp(predictor(test_x[:1]))\n",
        "\n",
        "test_y = test_y[:1]\n",
        "\n",
        "print(test_y_estimated.shape)\n",
        "print(test_y_estimated[0,:,0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "(1, 1024, 10)\n",
            "variable([1.948999  1.6216283 1.832916  ... 1.5367905 1.228483  1.0321773])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euolr1aREgoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "27c6abd3-fb61-4776-9068-970781f6f02f"
      },
      "source": [
        "y = test_y_estimated.data\n",
        "fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "fig_size[0] = 20\n",
        "fig_size[1] = 10\n",
        "i = 0\n",
        "b1 = plt.bar(range(y.shape[1]), y[0,:,i])\n",
        "b2 = plt.bar(range(y.shape[1]), test_y[0,:,i])\n",
        "plt.legend((b1, b2), ('estimated', 'observed'))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1908faf748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIcAAAJCCAYAAABahKemAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLlGN7IIElhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}